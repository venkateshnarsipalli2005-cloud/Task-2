{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3db87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. IMPORT REQUIRED LIBRARIES\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Scikit-learn preprocessing and models\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Evaluation metrics\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, roc_curve, confusion_matrix, classification_report\n",
    ")\n",
    "\n",
    "# Visualization\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96f06d7",
   "metadata": {},
   "source": [
    "# üîÆ Customer Churn Prediction System\n",
    "## End-to-End Machine Learning Pipeline\n",
    "\n",
    "This notebook builds a complete churn prediction system to identify customers likely to stop using a service. Using classification models and business-focused analysis, we'll uncover key churn drivers and create actionable insights for retention strategies.\n",
    "\n",
    "**Dataset**: Telco Customer Churn (7,043 customers)  \n",
    "**Target**: Binary classification (Churned: Yes/No)  \n",
    "**Models**: Logistic Regression, Random Forest, XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28224c88",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Customer Data\n",
    "\n",
    "Loading the Telco Customer Churn dataset from our data folder and examining its structure, shape, and key statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f059ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from CSV\n",
    "data_path = Path('data/telco_churn_processed.csv')\n",
    "if not data_path.exists():\n",
    "    data_path = Path('data/telco_churn.csv')\n",
    "\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"üìä Dataset Shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nData Types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nMissing Values:\")\n",
    "print(df.isnull().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67be5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\nüìà Summary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ff259e",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing\n",
    "\n",
    "Handling missing values, ensuring data quality, and preparing categorical variables for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c06672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values in detail\n",
    "print(\"Checking data quality...\")\n",
    "if 'TotalCharges' in df.columns:\n",
    "    df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "    if df['TotalCharges'].isnull().sum() > 0:\n",
    "        print(f\"‚ö†Ô∏è  Found {df['TotalCharges'].isnull().sum()} missing values in TotalCharges\")\n",
    "        df['TotalCharges'].fillna(df['MonthlyCharges'], inplace=True)\n",
    "        print(\"‚úì Filled missing TotalCharges with MonthlyCharges\")\n",
    "\n",
    "# Remove duplicates\n",
    "initial_shape = df.shape[0]\n",
    "df = df.drop_duplicates()\n",
    "print(f\"‚úì Removed {initial_shape - df.shape[0]} duplicate rows\")\n",
    "\n",
    "# Check categorical columns\n",
    "categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"\\nüìã Categorical Columns ({len(categorical_cols)}):\")\n",
    "for col in categorical_cols:\n",
    "    print(f\"  - {col}: {df[col].nunique()} unique values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefc4b04",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)\n",
    "\n",
    "Visualizing churn distribution and relationships between features and churn target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d31dd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn distribution\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Bar plot\n",
    "churn_counts = df['Churn'].value_counts()\n",
    "churn_counts.plot(kind='bar', ax=axes[0], color=['#2ecc71', '#e74c3c'], alpha=0.7)\n",
    "axes[0].set_title('Churn Distribution', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=0)\n",
    "for i, v in enumerate(churn_counts.values):\n",
    "    axes[0].text(i, v + 100, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# Pie chart\n",
    "churn_counts.plot(kind='pie', ax=axes[1], autopct='%1.1f%%', colors=['#2ecc71', '#e74c3c'])\n",
    "axes[1].set_title('Churn Proportion', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate churn rate\n",
    "churn_rate = (df['Churn'] == 'Yes').sum() / len(df) * 100\n",
    "print(f\"\\nüí° Churn Rate: {churn_rate:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a577019",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn by Contract Type\n",
    "if 'Contract' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    contract_churn = df.groupby('Contract')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100)\n",
    "    contract_churn.sort_values(ascending=False).plot(kind='barh', ax=ax, color='#e74c3c', alpha=0.7)\n",
    "    ax.set_title('Churn Rate by Contract Type', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Churn Rate (%)')\n",
    "    for i, v in enumerate(contract_churn.values):\n",
    "        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Churn by Internet Service\n",
    "if 'InternetService' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    internet_churn = df.groupby('InternetService')['Churn'].apply(lambda x: (x == 'Yes').sum() / len(x) * 100)\n",
    "    internet_churn.sort_values(ascending=False).plot(kind='barh', ax=ax, color='#3498db', alpha=0.7)\n",
    "    ax.set_title('Churn Rate by Internet Service', fontsize=12, fontweight='bold')\n",
    "    ax.set_xlabel('Churn Rate (%)')\n",
    "    for i, v in enumerate(internet_churn.values):\n",
    "        ax.text(v + 1, i, f'{v:.1f}%', va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b97307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tenure impact on churn\n",
    "if 'tenure' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for status in ['No', 'Yes']:\n",
    "        data = df[df['Churn'] == status]['tenure']\n",
    "        ax.hist(data, alpha=0.6, label=f'Churn: {status}', bins=30)\n",
    "    ax.set_xlabel('Tenure (months)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Tenure Distribution by Churn Status', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Monthly Charges impact\n",
    "if 'MonthlyCharges' in df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    for status in ['No', 'Yes']:\n",
    "        data = df[df['Churn'] == status]['MonthlyCharges']\n",
    "        ax.hist(data, alpha=0.6, label=f'Churn: {status}', bins=30)\n",
    "    ax.set_xlabel('Monthly Charges ($)')\n",
    "    ax.set_ylabel('Count')\n",
    "    ax.set_title('Monthly Charges Distribution by Churn Status', fontsize=12, fontweight='bold')\n",
    "    ax.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c8b042",
   "metadata": {},
   "source": [
    "## 5. Feature Engineering\n",
    "\n",
    "Creating new features to enhance model performance and interpretability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f38ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy for feature engineering\n",
    "df_features = df.copy()\n",
    "\n",
    "# Tenure-based features\n",
    "if 'tenure' in df_features.columns:\n",
    "    df_features['tenure_group'] = pd.cut(df_features['tenure'], \n",
    "                                          bins=[0, 6, 12, 24, 73],\n",
    "                                          labels=['0-6m', '6-12m', '1-2y', '2+y'])\n",
    "    print(\"‚úì Created tenure_group feature\")\n",
    "\n",
    "# Charge-based features\n",
    "if 'MonthlyCharges' in df_features.columns and 'TotalCharges' in df_features.columns:\n",
    "    df_features['avg_monthly_to_total'] = df_features['MonthlyCharges'] / (df_features['TotalCharges'] + 1)\n",
    "    df_features['total_charges_group'] = pd.qcut(df_features['TotalCharges'], \n",
    "                                                   q=4, \n",
    "                                                   labels=['Low', 'Medium', 'High', 'VeryHigh'],\n",
    "                                                   duplicates='drop')\n",
    "    print(\"‚úì Created charge ratio and charge group features\")\n",
    "\n",
    "# Service adoption score\n",
    "service_cols = [col for col in df_features.columns if 'Service' in col or 'Security' in col or 'Support' in col]\n",
    "if service_cols:\n",
    "    df_features['service_adoption_score'] = df_features[service_cols].apply(lambda x: (x == 'Yes').sum(), axis=1)\n",
    "    print(f\"‚úì Created service adoption score from {len(service_cols)} service columns\")\n",
    "\n",
    "print(f\"\\nüìù New feature columns: {df_features.columns.tolist()[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3573ec64",
   "metadata": {},
   "source": [
    "## 6. Prepare Data for Modeling\n",
    "\n",
    "Encoding categorical variables and scaling numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d330fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare features and target\n",
    "X = df_features.copy()\n",
    "\n",
    "# Drop non-predictive columns\n",
    "drop_columns = ['customerID', 'Churn', 'tenure_group', 'total_charges_group']\n",
    "X = X.drop(columns=[col for col in drop_columns if col in X.columns])\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "print(f\"Encoding {len(categorical_cols)} categorical columns...\")\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "    print(f\"  ‚úì {col}\")\n",
    "\n",
    "# Handle NaN values\n",
    "X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "# Target variable\n",
    "y = df_features['Churn'].map({'No': 0, 'Yes': 1})\n",
    "\n",
    "print(f\"\\n‚úì Final feature matrix shape: {X.shape}\")\n",
    "print(f\"‚úì Target variable shape: {y.shape}\")\n",
    "print(f\"‚úì Class distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aed7e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Feature Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"‚úì Train set shape: {X_train_scaled.shape}\")\n",
    "print(f\"‚úì Test set shape: {X_test_scaled.shape}\")\n",
    "print(f\"‚úì Train churn distribution: {np.bincount(y_train)}\")\n",
    "print(f\"‚úì Test churn distribution: {np.bincount(y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d575d6bb",
   "metadata": {},
   "source": [
    "## 7. Build and Train Classification Models\n",
    "\n",
    "Training three classification models: Logistic Regression, Random Forest, and XGBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229a23b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üöÄ Training Classification Models...\\n\")\n",
    "\n",
    "models = {}\n",
    "predictions = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "print(\"1Ô∏è‚É£  Logistic Regression...\")\n",
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "models['Logistic Regression'] = lr\n",
    "predictions['Logistic Regression'] = {\n",
    "    'y_pred': lr.predict(X_test_scaled),\n",
    "    'y_pred_proba': lr.predict_proba(X_test_scaled)[:, 1]\n",
    "}\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# 2. Random Forest\n",
    "print(\"2Ô∏è‚É£  Random Forest...\")\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1, max_depth=15)\n",
    "rf.fit(X_train_scaled, y_train)\n",
    "models['Random Forest'] = rf\n",
    "predictions['Random Forest'] = {\n",
    "    'y_pred': rf.predict(X_test_scaled),\n",
    "    'y_pred_proba': rf.predict_proba(X_test_scaled)[:, 1]\n",
    "}\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "# 3. XGBoost\n",
    "print(\"3Ô∏è‚É£  XGBoost...\")\n",
    "xgb = XGBClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=7,\n",
    "    learning_rate=0.05,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    eval_metric='logloss',\n",
    "    verbosity=0\n",
    ")\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "models['XGBoost'] = xgb\n",
    "predictions['XGBoost'] = {\n",
    "    'y_pred': xgb.predict(X_test_scaled),\n",
    "    'y_pred_proba': xgb.predict_proba(X_test_scaled)[:, 1]\n",
    "}\n",
    "print(\"   ‚úì Model trained\")\n",
    "\n",
    "print(\"\\n‚úì All models trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1886cf6b",
   "metadata": {},
   "source": [
    "## 8. Model Evaluation and Comparison\n",
    "\n",
    "Computing and comparing key metrics for all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17584050",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä MODEL EVALUATION RESULTS\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for model_name in models.keys():\n",
    "    y_pred = predictions[model_name]['y_pred']\n",
    "    y_pred_proba = predictions[model_name]['y_pred_proba']\n",
    "    \n",
    "    results[model_name] = {\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1-Score': f1_score(y_test, y_pred),\n",
    "        'ROC-AUC': roc_auc_score(y_test, y_pred_proba),\n",
    "        'Confusion Matrix': confusion_matrix(y_test, y_pred)\n",
    "    }\n",
    "    \n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(f\"  Accuracy:  {results[model_name]['Accuracy']:.4f}\")\n",
    "    print(f\"  Precision: {results[model_name]['Precision']:.4f}\")\n",
    "    print(f\"  Recall:    {results[model_name]['Recall']:.4f}\")\n",
    "    print(f\"  F1-Score:  {results[model_name]['F1-Score']:.4f}\")\n",
    "    print(f\"  ROC-AUC:   {results[model_name]['ROC-AUC']:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32679daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison dataframe\n",
    "results_df = pd.DataFrame(results).T\n",
    "print(\"\\nüìà Model Performance Comparison:\")\n",
    "print(results_df[['Accuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']].round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3701069f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization: Model Comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Metrics comparison\n",
    "metrics_plot_df = results_df[['Accuracy', 'ROC-AUC', 'Precision', 'Recall', 'F1-Score']]\n",
    "metrics_plot_df.plot(kind='bar', ax=axes[0], alpha=0.7)\n",
    "axes[0].set_title('Model Performance Metrics Comparison', fontsize=12, fontweight='bold')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_xticklabels(axes[0].get_xticklabels(), rotation=45)\n",
    "axes[0].grid(alpha=0.3)\n",
    "axes[0].legend(loc='lower right')\n",
    "\n",
    "# ROC-AUC Comparison\n",
    "best_model = results_df['ROC-AUC'].idxmax()\n",
    "for model_name in models.keys():\n",
    "    y_pred_proba = predictions[model_name]['y_pred_proba']\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba)\n",
    "    auc_score = results[model_name]['ROC-AUC']\n",
    "    linewidth = 2.5 if model_name == best_model else 1.5\n",
    "    linestyle = '-' if model_name == best_model else '--'\n",
    "    axes[1].plot(fpr, tpr, label=f'{model_name} (AUC={auc_score:.3f})', linewidth=linewidth, linestyle=linestyle)\n",
    "\n",
    "axes[1].plot([0, 1], [0, 1], 'k--', label='Random Classifier', alpha=0.5)\n",
    "axes[1].set_xlabel('False Positive Rate')\n",
    "axes[1].set_ylabel('True Positive Rate')\n",
    "axes[1].set_title('ROC Curves', fontsize=12, fontweight='bold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nüèÜ Best Model: {best_model} (ROC-AUC: {results[best_model]['ROC-AUC']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3383c685",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "Identifying which features have the greatest impact on churn predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c7a5e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance from tree-based models\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Random Forest Feature Importance\n",
    "rf_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': models['Random Forest'].feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[0].barh(rf_importance['feature'], rf_importance['importance'], color='#3498db', alpha=0.7)\n",
    "axes[0].set_title('Random Forest - Top 15 Features', fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Importance')\n",
    "axes[0].invert_yaxis()\n",
    "\n",
    "# XGBoost Feature Importance\n",
    "xgb_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': models['XGBoost'].feature_importances_\n",
    "}).sort_values('importance', ascending=False).head(15)\n",
    "\n",
    "axes[1].barh(xgb_importance['feature'], xgb_importance['importance'], color='#e74c3c', alpha=0.7)\n",
    "axes[1].set_title('XGBoost - Top 15 Features', fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Importance')\n",
    "axes[1].invert_yaxis()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Random Forest - Top 10 Features:\")\n",
    "print(rf_importance.head(10).to_string(index=False))\n",
    "print(\"\\nüìä XGBoost - Top 10 Features:\")\n",
    "print(xgb_importance.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45823a0a",
   "metadata": {},
   "source": [
    "## 10. Churn Probability and Risk Segmentation\n",
    "\n",
    "Generating churn probabilities and categorizing customers into risk tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f84c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate churn probabilities using best model\n",
    "best_model_obj = models[best_model]\n",
    "best_churn_proba = predictions[best_model]['y_pred_proba']\n",
    "\n",
    "# Create risk segmentation\n",
    "def categorize_risk(prob):\n",
    "    if prob >= 0.7:\n",
    "        return 'High Risk'\n",
    "    elif prob >= 0.4:\n",
    "        return 'Medium Risk'\n",
    "    else:\n",
    "        return 'Low Risk'\n",
    "\n",
    "risk_categories = [categorize_risk(p) for p in best_churn_proba]\n",
    "\n",
    "# Add to test set\n",
    "test_results = pd.DataFrame({\n",
    "    'CustomerIndex': y_test.index,\n",
    "    'Actual_Churn': y_test.values,\n",
    "    'Predicted_Churn': predictions[best_model]['y_pred'],\n",
    "    'Churn_Probability': best_churn_proba,\n",
    "    'Risk_Category': risk_categories\n",
    "})\n",
    "\n",
    "print(\"üéØ Risk Segmentation Results:\")\n",
    "print(f\"\\n{test_results['Risk_Category'].value_counts()}\")\n",
    "print(f\"\\nüìä Risk Category Distribution:\")\n",
    "print(test_results['Risk_Category'].value_counts(normalize=True).round(3))\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nüìå Sample High-Risk Customers:\")\n",
    "high_risk = test_results[test_results['Risk_Category'] == 'High Risk'].head(10)\n",
    "print(high_risk[['Actual_Churn', 'Predicted_Churn', 'Churn_Probability', 'Risk_Category']].to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52205fd",
   "metadata": {},
   "source": [
    "## 11. Visualize Key Churn Drivers\n",
    "\n",
    "Comprehensive visualizations of model performance and churn insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635d5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Visualization Dashboard\n",
    "fig = plt.figure(figsize=(16, 12))\n",
    "gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "\n",
    "# 1. Confusion Matrix (Best Model)\n",
    "ax1 = fig.add_subplot(gs[0, 0])\n",
    "cm = results[best_model]['Confusion Matrix']\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1, cbar=False)\n",
    "ax1.set_title(f'Confusion Matrix - {best_model}', fontweight='bold')\n",
    "ax1.set_ylabel('True Label')\n",
    "ax1.set_xlabel('Predicted Label')\n",
    "\n",
    "# 2. Precision-Recall Trade-off\n",
    "ax2 = fig.add_subplot(gs[0, 1])\n",
    "precision_vals = [results[m]['Precision'] for m in models.keys()]\n",
    "recall_vals = [results[m]['Recall'] for m in models.keys()]\n",
    "ax2.scatter(recall_vals, precision_vals, s=300, alpha=0.6, c=['#3498db', '#2ecc71', '#e74c3c'])\n",
    "for i, name in enumerate(models.keys()):\n",
    "    ax2.annotate(name, (recall_vals[i], precision_vals[i]), fontsize=9, ha='center', fontweight='bold')\n",
    "ax2.set_xlabel('Recall')\n",
    "ax2.set_ylabel('Precision')\n",
    "ax2.set_title('Precision vs Recall Trade-off', fontweight='bold')\n",
    "ax2.grid(alpha=0.3)\n",
    "ax2.set_xlim([0, 1])\n",
    "ax2.set_ylim([0, 1])\n",
    "\n",
    "# 3. Risk Category Distribution\n",
    "ax3 = fig.add_subplot(gs[0, 2])\n",
    "risk_counts = test_results['Risk_Category'].value_counts()\n",
    "colors_risk = {'High Risk': '#e74c3c', 'Medium Risk': '#f39c12', 'Low Risk': '#2ecc71'}\n",
    "ax3.bar(risk_counts.index, risk_counts.values, color=[colors_risk[x] for x in risk_counts.index], alpha=0.7)\n",
    "ax3.set_title('Risk Category Distribution', fontweight='bold')\n",
    "ax3.set_ylabel('Count')\n",
    "for i, v in enumerate(risk_counts.values):\n",
    "    ax3.text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
    "\n",
    "# 4. Churn Probability Distribution\n",
    "ax4 = fig.add_subplot(gs[1, 0])\n",
    "ax4.hist(best_churn_proba[y_test == 0], bins=30, alpha=0.6, label='Retained', color='#2ecc71')\n",
    "ax4.hist(best_churn_proba[y_test == 1], bins=30, alpha=0.6, label='Churned', color='#e74c3c')\n",
    "ax4.set_xlabel('Churn Probability')\n",
    "ax4.set_ylabel('Count')\n",
    "ax4.set_title('Predicted Churn Probability Distribution', fontweight='bold')\n",
    "ax4.legend()\n",
    "ax4.axvline(x=0.5, color='black', linestyle='--', linewidth=1, alpha=0.5)\n",
    "\n",
    "# 5. Model Accuracy Comparison\n",
    "ax5 = fig.add_subplot(gs[1, 1])\n",
    "accuracies = [results[m]['Accuracy'] for m in models.keys()]\n",
    "ax5.bar(models.keys(), accuracies, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.7)\n",
    "ax5.set_ylabel('Accuracy')\n",
    "ax5.set_title('Model Accuracy Comparison', fontweight='bold')\n",
    "ax5.set_ylim([0.7, 1])\n",
    "for i, v in enumerate(accuracies):\n",
    "    ax5.text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "ax5.set_xticklabels(ax5.get_xticklabels(), rotation=45)\n",
    "\n",
    "# 6. ROC-AUC Comparison\n",
    "ax6 = fig.add_subplot(gs[1, 2])\n",
    "auc_scores = [results[m]['ROC-AUC'] for m in models.keys()]\n",
    "ax6.bar(models.keys(), auc_scores, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.7)\n",
    "ax6.set_ylabel('ROC-AUC Score')\n",
    "ax6.set_title('ROC-AUC Comparison', fontweight='bold')\n",
    "ax6.set_ylim([0.7, 1])\n",
    "for i, v in enumerate(auc_scores):\n",
    "    ax6.text(i, v + 0.01, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "ax6.set_xticklabels(ax6.get_xticklabels(), rotation=45)\n",
    "\n",
    "# 7. F1-Score Comparison\n",
    "ax7 = fig.add_subplot(gs[2, 0])\n",
    "f1_scores = [results[m]['F1-Score'] for m in models.keys()]\n",
    "ax7.bar(models.keys(), f1_scores, color=['#3498db', '#2ecc71', '#e74c3c'], alpha=0.7)\n",
    "ax7.set_ylabel('F1-Score')\n",
    "ax7.set_title('F1-Score Comparison', fontweight='bold')\n",
    "ax7.set_ylim([0.4, 0.8])\n",
    "for i, v in enumerate(f1_scores):\n",
    "    ax7.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "ax7.set_xticklabels(ax7.get_xticklabels(), rotation=45)\n",
    "\n",
    "# 8. Churn Probability by Risk Category\n",
    "ax8 = fig.add_subplot(gs[2, 1])\n",
    "risk_order = ['Low Risk', 'Medium Risk', 'High Risk']\n",
    "churn_by_risk = [best_churn_proba[test_results['Risk_Category'] == cat].mean() for cat in risk_order]\n",
    "ax8.bar(risk_order, churn_by_risk, color=['#2ecc71', '#f39c12', '#e74c3c'], alpha=0.7)\n",
    "ax8.set_ylabel('Average Churn Probability')\n",
    "ax8.set_title('Average Churn Probability by Risk Category', fontweight='bold')\n",
    "for i, v in enumerate(churn_by_risk):\n",
    "    ax8.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
    "\n",
    "# 9. Actual Churn Rate by Risk Category\n",
    "ax9 = fig.add_subplot(gs[2, 2])\n",
    "actual_churn_by_risk = [y_test[test_results['Risk_Category'] == cat].mean() for cat in risk_order]\n",
    "ax9.bar(risk_order, actual_churn_by_risk, color=['#2ecc71', '#f39c12', '#e74c3c'], alpha=0.7)\n",
    "ax9.set_ylabel('Actual Churn Rate')\n",
    "ax9.set_title('Actual Churn Rate by Risk Category', fontweight='bold')\n",
    "for i, v in enumerate(actual_churn_by_risk):\n",
    "    ax9.text(i, v + 0.02, f'{v:.1%}', ha='center', fontweight='bold')\n",
    "\n",
    "fig.suptitle('üîÆ Churn Prediction - Comprehensive Dashboard', fontsize=16, fontweight='bold', y=0.995)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6893c3df",
   "metadata": {},
   "source": [
    "## 12. Generate Business Insights Report\n",
    "\n",
    "Key findings and actionable recommendations for decision-makers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47d0c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"üíº BUSINESS INSIGHTS REPORT - CHURN PREDICTION SYSTEM\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüìä EXECUTIVE SUMMARY\")\n",
    "print(f\"-\" * 80)\n",
    "print(f\"Model: {best_model}\")\n",
    "print(f\"Overall Churn Rate: {churn_rate:.1f}%\")\n",
    "print(f\"Model Accuracy: {results[best_model]['Accuracy']:.1%}\")\n",
    "print(f\"Model ROC-AUC: {results[best_model]['ROC-AUC']:.1%}\")\n",
    "\n",
    "print(f\"\\nüéØ CUSTOMER SEGMENTATION\")\n",
    "print(f\"-\" * 80)\n",
    "for risk_cat in ['High Risk', 'Medium Risk', 'Low Risk']:\n",
    "    count = len(test_results[test_results['Risk_Category'] == risk_cat])\n",
    "    pct = count / len(test_results) * 100\n",
    "    print(f\"{risk_cat:15} : {count:4} customers ({pct:5.1f}%)\")\n",
    "\n",
    "print(f\"\\nüîç KEY CHURN DRIVERS (XGBoost)\")\n",
    "print(f\"-\" * 80)\n",
    "top_features = xgb_importance.head(5)\n",
    "for idx, row in top_features.iterrows():\n",
    "    print(f\"  {row['feature']:25} ‚Üí Importance: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\nüí° ACTIONABLE RECOMMENDATIONS\")\n",
    "print(f\"-\" * 80)\n",
    "print(f\"\"\"\n",
    "1. üéØ TARGET HIGH-RISK CUSTOMERS\n",
    "   - Identified {len(test_results[test_results['Risk_Category'] == 'High Risk'])} high-risk customers\n",
    "   - Implement retention campaigns focusing on top churn drivers\n",
    "   - Offer personalized retention incentives\n",
    "\n",
    "2. üìû PROACTIVE OUTREACH\n",
    "   - Contact customers before churn occurs\n",
    "   - Use predicted probabilities to prioritize engagement\n",
    "   - Focus resources on medium-risk customers (highest ROI opportunity)\n",
    "\n",
    "3. üîß PRODUCT IMPROVEMENTS\n",
    "   - Analyze features driving churn (tenure, charges, contract type)\n",
    "   - Improve onboarding for new customers (tenure < 6 months)\n",
    "   - Review pricing strategy for high-charge customers\n",
    "\n",
    "4. üìà MONITORING & IMPROVEMENT\n",
    "   - Track model performance over time\n",
    "   - Retrain quarterly with new customer data\n",
    "   - Monitor false positives to avoid over-retention spending\n",
    "\n",
    "5. üí∞ FINANCIAL IMPACT\n",
    "   - Prioritize retention of high-value customers\n",
    "   - Allocate retention budget to high-risk segment\n",
    "   - Expected ROI: Cost of retention << Cost of acquisition\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\n‚úÖ MODEL RELIABILITY METRICS\")\n",
    "print(f\"-\" * 80)\n",
    "print(f\"Precision (Identifying actual churners): {results[best_model]['Precision']:.1%}\")\n",
    "print(f\"  ‚Üí Of customers we predict will churn, {results[best_model]['Precision']:.1%} actually do\")\n",
    "print(f\"\\nRecall (Catching all churners): {results[best_model]['Recall']:.1%}\")\n",
    "print(f\"  ‚Üí We successfully identify {results[best_model]['Recall']:.1%} of all customers who churn\")\n",
    "print(f\"\\nF1-Score (Balance): {results[best_model]['F1-Score']:.3f}\")\n",
    "print(f\"  ‚Üí Good balance between precision and recall\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
